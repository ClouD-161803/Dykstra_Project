\documentclass[hidelinks]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% START CUSTOM INCLUDES & DEFINITIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath,amssymb,amsfonts,amsthm}
%\usepackage{parskip} %noident everywhere
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{overpic}
\usepackage{mymath}
\usepackage{nth}
\usepackage{caption}
\usepackage{todonotes}
\usepackage{fullpage}
\usepackage{arydshln} % dashed line in array
\usepackage{MnSymbol} % anti-diag dots
%\usepackage{showlabels} % show equation and figure labels
\usepackage{subcaption}
\usepackage{varwidth, tikz}
\usetikzlibrary{shapes, arrows, shapes.misc, arrows.meta, positioning, matrix, calc, fit, fadings, patterns}
\usetikzlibrary{calc,patterns,decorations.pathmorphing,decorations.markings,arrows, arrows.meta}
\usepackage[export]{adjustbox}
\usepackage{placeins}
%\setlength{\parindent}{0pt} 
\usepackage{tabto}

\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ALG STUFF
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{algorithm}
\usepackage{algorithmic}
\newcommand{\algorithmicbreak}{\textbf{break}}
\newcommand{\Break}{\State \algorithmicbreak}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\makeatletter
\newcommand{\algrule}[1][.2pt]{{\color{black!10!white}{\par\vskip.1\baselineskip\hrule height #1\par\vskip.1\baselineskip}}}
\makeatother
%\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END CUSTOM INCLUDES & DEFINITIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pdfobjcompresslevel=0

\title{Dykstra's Alternating Projection for Polyhedral Sets\thanks{This research was supported by the Keble College Small Research Grant (KSRG118).}}
\author{Claudio Vestini and Idris Kempf}
\date{Michaelmas Term 2024}
\begin{document}
\maketitle

\section{Summary}



\section{Introduction}

Euclidean projections are ubiquitous in engineering, optimisation, and machine learning, playing a central role in many algorithms for solving problems constrained by complex sets. Mathematically, a projection of a point $x^\circ\in\R^n$ onto a closed convex set $\mathcal{H}\subset \R^p$ is defined as the point $x^\star\eqdef \mathcal{P}_{\mathcal{H}}(x)$ that minimises the Euclidean distance between $x^\circ$ and any point in $\mathcal{H}$:
\begin{align}\label{eq:projection}
\mathcal{P}_{\mathcal{H}}(x)\eqdef \argmin_{x\in\mathcal{H}}\twonorm{x-x^\circ}.
\end{align}
By the convexity of the set $\mathcal{H}$, problem~\eqref{eq:projection} admits a unique solution~\cite[Ch.\ 3.2]{BAUSCHKEBOOK}. Here, we assume that $\mathcal{H}$ is a convex polyhedral set that can be represented as
\begin{align}\label{eq:polyhedron}
\mathcal{H}\eqdef\set{x\in\R^p}{A x \leq c},
\end{align}
where $\inR{A}{n}{p}$ and $c\in\R^n$. Each row of $\mathcal{H}$ corresponds to a half-space $\mathcal{H}_i$,
\begin{align}\label{eq:sets_i}
\mathcal{H}_i\eqdef\set{x\in\R^p}{\trans{f_i}x \leq c_i},
\end{align}
where $i=1,\dots,n$ and $f_i$, $\twonorm{f_i}=1$, is the normal vector of the plane $H_i\eqdef\set{x\in\R^p}{\trans{f_i}x = c_i}$. The polyhedral set~\eqref{eq:polyhedron} can also be represented as the intersection of the half-spaces $\mathcal{H}_i$, i.e.\ $\mathcal{H}=\bigcap_{i=0}^{n-1}\mathcal{H}_i$. In many engineering applications, constraint sets can be approximated using~\eqref{eq:polyhedron}.

While for some sets the solution of~\eqref{eq:polyhedron} can be obtained explicitly and in closed form, e.g., when $\mathcal{H}$ is an $n$-dimensional cube, no closed-form solution is known for arbitrary polyhedral sets. In these cases, the solution can be obtained using a solver for constrained quadratic programs. To solve~\eqref{eq:projection}, most solvers require introducing an additional variable $z\eqdef Ax$ that is projected onto the set $\set{z\in\R^n}{z \leq c}$, for which an explicit solution exists. However, for large $n$, this variable augmentation can reduce the computational efficiency, in particular when the projection is part of a larger iterative algorithm.

As an alternative to variable augmentation, problem~\eqref{eq:projection} can be solved using \emph{Dykstra's Alternating Projection Algorithm}~\cite{DYKSTRA}. Dykstra's algorithm, first published in 1983, extends von Neumann's \emph{Method of Alternating Projections} (MAP)~\cite{NEUMANN}, which is designed to find a point lying in the intersection of $n$ closed convex sets by cyclically projecting onto each individual set. While von Neumann's algorithm identifies \emph{some} point in the intersection, Dykstra's algorithm determines the Euclidean projection~\eqref{eq:projection}. Both algorithms circumvent the potentially complex projection $\mathcal{P}_\mathcal{H}$ by iteratively applying the (known) projections $\mathcal{P}_{\mathcal{H}_0},\dots,\mathcal{P}_{\mathcal{H}_{n-1}}$. 

Although Dykstra's algorithm is proven to eventually converge to the projection, it has shown to be prone to \emph{stalling}~\cite{DYKSTRASTALLING} for certain sets, including polyhedral sets like~\eqref{eq:polyhedron}. In such cases, the iterates of Dykstra's method remain unchanged for a number of iterations. The duration of the stalling period cannot be determined \emph{a priori}, and depending on the starting point, can be arbitrary long. This phenomenon hinders the application of Dykstra's method in practice. Additionally, the algorithm \emph{cannot} be run for a fixed number of iterations with a guarantee that the output will be closer to the projection than the initial point -- a guarantee typically required when embedding Dykstra's method in iterative schemes, such as gradient methods~\cite{FGMPROJECTION}.

\section{Dykstra's Alternating Projection}\label{sec: dykstra}

Given $n$ convex sets $\mathcal{H}_0,\dots,\mathcal{H}_{n-1}$, Dykstra's alternating projection algorithm~\cite{DYKSTRAPERKINS} finds the orthogonal projection $x^\star$ of $x^\circ$ onto $\mathcal{H}\eqdef{\bigcap}_{i=0}^{n-1} \mathcal{H}_i$ by generating a series of iterates \{$x_{m}$\} using the scheme
\begin{subequations}\label{eq:dykstra}
\begin{align}
x_{m+1}&=\mathcal{P}_{\mathcal{H}_{[m]}}\left(x_{m}+e_{m-n}\right),\label{eq:dykstra:proj}\\
e_m&=e_{m-n}+x_{m}-x_{m+1}\label{eq:dykstra:error},
\end{align}
\end{subequations}
where $[m]\eqdef m \, \text{mod} \, n$, $x_0=x$, $\mathcal{P}_{[m]}\eqdef\mathcal{P}_{\mathcal{H}_{[m]}}$, and the auxiliary variables $e_m$ are initialised as
\begin{align}\label{eq:initial error}
&e_{-n} = e_{-(n-1)} = ... = e_{-1} = 0.
\end{align}

Note that von Neumann's MAP can be obtained from~\eqref{eq:dykstra} by setting $e_m \equiv 0\quad\forall m$. The Boyle-Dykstra theorem~\cite{DYKSTRA} implies that $\lim_{m\rightarrow\infty}\anynorm{x_m-\mathcal{P}_\mathcal{H}(x)}=0$. For a finite number of iterations, there is no guarantee that $x_m\in\mathcal{H}$ nor that $x_m\neq x$. 

\subsection{The Polyhedral Case}

For polyhedral sets~\eqref{eq:sets_i}, the projection step~\eqref{eq:dykstra:proj} can be simplified to
\begin{align}\label{eq:dykstra:proj:poly}
x_{m+1}=
\begin{cases}
x_{m}+e_{m-n} & \text{if } x_{m}+e_{m-n}\in\mathcal{H}_{[m]}\\
x_{m}+e_{m-n} - \left((x_{m}+e_{m-n})^\Tr f_{[m]} - c_{[m]}\right) f_{[m]} & \text{if } x_{m}+e_{m-n}\not\in\mathcal{H}_{[m]}
\end{cases},
\end{align}
and the update for the auxiliary vector to
\begin{align}\label{eq:dykstra:error:poly}
e_m=
\begin{cases}
0 & \text{if } x_{m}+e_{m-n}\in\mathcal{H}_{[m]},\\
\left((x_{m}+e_{m-n})^\Tr f_{[m]} - c_{[m]}\right) f_{[m]} & \text{if } x_{m}+e_{m-n}\not\in\mathcal{H}_{[m]},
\end{cases}.
\end{align}
The auxiliary vector $e_m$ is either $0$ or parallel to $f_{[m]}$, so that it can be represented as $e_m = k_m f_{[m]}$ with $k_m=\text{dist}_{\mathcal{H}_{[m]}}(x_{m-1}+e_{m-n})$, further simplifying~\eqref{eq:dykstra:error:poly} to
\begin{align}\label{eq:km}
k_m = k_{m-n} + x_m^\Tr f_{[m]} - c_{[m]}.
\end{align}

The convergence of Dykstra's iterates to the Eucledian projection has been analysed in~\cite{DYKSTRAPOLY2,DYKSTRAPOLY,DYKSTRAPERKINS} for polyhedral sets. The proof is based on partitioning the sets into inactive ($x^\star\not\in H_i$) and active sets ($x^\star\in H_i$), i.e.\
\begin{align}
&A=\set{i\in\lbrace 0,\dots,n-1\rbrace}{x_\infty\in H_i},
&B=\lbrace 0,\dots,n-1\rbrace\backslash A,
\end{align}
where $x_\infty=\lim_{m\rightarrow\infty}x_m$. It can be shown that there exists a number $N_1$ such that whenever
\begin{align}
[m]\in B,\quad m\geq N_1\quad\Rightarrow\quad x_m=x_{m-1},\quad e_m=0,
\end{align}
i.e. the half-spaces that become ``inactive'' remain inactive. Furthermore, there exists $N_2\geq N_1$ such that whenever $n\geq N_2$, it holds that
\begin{align}\label{eq:dykstra:error:poly}
\twonorm{x_{m+n}-x_\infty}\leq\alpha_{[m]}\twonorm{x_m-x_\infty},
\end{align}
where $0\leq\alpha_{[m]}<1$ are numbers related to angles between half-spaces. The number $N_2$ describes the iteration from which on the algorithm has determined the inactive half-spaces. Finally, it is shown that the iterates of the algorithm satisfy the following inequality:
\begin{theorem}[Deutsch and Hundal~\cite{DYKSTRAPOLY}]
There exist constants $0\leq c < 1$ and $\rho > 0$ such that
\begin{align*}
\anynorm{x_m -x_\infty} \leq \rho c^m.
\end{align*}
\end{theorem}
The factor $c$ can be estimated from the smallest $\alpha_{[m]}$, which is characterized by the angle between certain subspaces (subspaces formed by the ``active'' halfspaces). The factor $\alpha_{[m]}$ can be upper-bounded by considering the ``worst'' angles in the polyhedron. The constant $\rho$, however, depends on an unknown iteration number $N_3\geq N_2$ and on the starting point $x^\circ$, and can therefore not be computed in advance~\cite{DYKSTRAPERKINS,XUPOLY}. In the case of stalling, the variable $\rho$ can become arbitrarily large, making the application of Dykstra's method difficult in practice. The authors of~\cite{DYKSTRAPERKINS} proposed a combined Dysktra-conjugate-gradient method that allows for computing an upper bound on $\anynorm{x_m -x_\infty}$. The authors of~\cite{XUPOLY} proposed an alternative algorithm called \emph{successive approximate algorithm}, which promises fast convergence, conditioned on knowing a point $x\in\mathcal{H}$ in advance.

%\begin{remark}[Random thoughts]
%Dykstra's method could be interpreted as an autonomous non-linear discrete-time system with initial condition $x^\circ$. For $m\geq N_2$, I believe that the discrete-time system becomes \emph{linear} and could be reformulated as $x_{m+n} = G x_m + b$.
%Since by the Boyle-Dykstra theorem $x_{m+n}$ necessarily converges to the projection for $n\rightarrow\infty$, the matrix $G$ must be Schur stable, so that the projection can be obtained from $x^\star = \inv{\left(I-G\right)} b$. The question is whether $N_2$ can be detected (may have been answered in the literature already).
%\end{remark}

\subsection{Stalling}

In~\cite{DYKSTRASTALLING}, the behaviour of Dykstra's method is analysed for two sets. The authors give conditions on Dykstra's algorithm for (i) finite convergence, (ii) infinite convergence, and (iii) stalling followed by infinite convergence. A specific example is given for the case that the set is provided by the intersection of a line with a unit box in $\R^2$ ($\mathcal{H}$ is a polyhedron). It can be shown that cases (i)--(iii) depend on the starting point $x_0$, and one can determine the 3 regions shown in Figure~\ref{fig:region} that yield different convergence behaviour. Convergence case (i) is obtained when starting in the green region, case (ii) when starting in the blue region, and case (iii) when starting in the red region.

To understand the stalling effect, consider Figure~\ref{fig:stalling}, which shows the first iterations of Dykstra's algorithm with starting point in the red region. Note that the outcome of Dykstra's algorithm depends on the order of the sets $\mathcal{H}_i,\dots,\mathcal{H}_n$. In Figure~\ref{fig:stalling}, the algorithm starts by projecting onto the box and then onto the line. It can be seen that for the first 6 iterations\footnote{By one iteration we mean one cycle of $n$ projections here.}, Dykstra's algorithm returns the top left corner of the box (``stalling''). The authors also determine the exact number of iterations required to break free from the red region, and show that if the starting point is arbitrarily far to the left, the algorithm will need an arbitrarily large iteration number to break free from the red region.

% Figure demonstrating the stalling problem
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{StallingRegionsHand.png}
        \caption{Line-box example with different regions that yield different convergence properties.}
        \label{fig:region}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{DifferentSequences.png}
        \caption{Stalling for the line-box example when $x_0$ is in the red region.}
        \label{fig:stalling}
    \end{subfigure}
    \caption{A demonstration of the stalling problem for a box and a line. Note how MAP applied to the same constraint sets would not result in any stalling: MAP follows the green line, and subsequently converges via the blue line path. Figure taken from~\cite{DYKSTRASTALLING}.}
    \label{fig:baushkeStall}
\end{figure}

\section{Main Result: Fast Forwarding Stalling Period}

By graphical examination of Figure~\ref{fig:baushkeStall} and formulae~\eqref{eq:dykstra:proj:poly}-\eqref{eq:km}, the following observations can be made:
\begin{enumerate}
\item The stalling period continues until one of the active half-spaces becomes inactive. This is a necessary condition.
\item During stalling, it holds that $x_m\equiv x_{m-n}\,\forall m$, so that every iteration, a constant vector $\Delta_m\eqdef x_{m-1}-x_m$ is added to $e_m$.
\end{enumerate}

These observations are formalised in the following theorem:
\begin{theorem}[Length of Stalling Period]\label{thm:nstall}
Suppose that at iteration $m$, the algorithm stalls, i.e.\ $x_{m+i}=x_{m-n+i}\,\forall i=0,\dots,n-1$. Then, the length of the stalling period is given by
\begin{align}\label{eq:nstall}
N_{stall}\eqdef\argmin_{i\in\mathcal{S}} \left\lfloor -k_{m-n+i} / \left(x_{m+i}^\Tr f_{[m+i]} - c_{[m+i]}\right)\right\rfloor,
\end{align}
where $\mathcal{S}\eqdef\set{i\in \mathcal{A}_m}{x_{m-n+i}^\Tr f_{[m+i]} - c_{[m+i]} < 0}$ and $\mathcal{A}_m\eqdef\set{i\in\lbrace 0,\dots,n-1\rbrace}{x_{m+i}+e_{m-n}\not\in\mathcal{H}_{[m+i]}}$.
\end{theorem}
\begin{proof}
Note that the existence of a finite number $N_{stall}$ is a consequence of the Boyle-Dykstra theorem. According to~\eqref{eq:dykstra:proj:poly}, the stalling period will terminate once one half-space becomes inactive, i.e. $x_{m+j}+e_{m-n+j}\not\in\mathcal{H}_{[m-n+j]}$ for some $[m-n+j]\in\mathcal{A}_m$. According to~\eqref{eq:km}, the only half-spaces that can become inactive are those for which $\delta k_{i} \eqdef x_{m+i}^\Tr f_{[m+i]} - c_{[m+i]} < 0$, which is, by definition, a constant during stalling. The length of the stalling period can therefore be obtained from choosing the smallest possible integer $N$ for which
\begin{align*}
k_{m-n+i}+N\left(x_{m+i}^\Tr f_{[m+i]} - c_{[m+i]}\right) < 0,\qquad [m+i]\in\mathcal{A}_m,
\end{align*}
which can be reformulated as in~\eqref{eq:nstall}.
\end{proof}

By Theorem~\eqref{thm:nstall}, the stalling period can be fast-forwarded by applying $N_{stall}$ constant increments to each auxiliary variable $k_m$ from~\eqref{eq:km}. This is illustrated for the line-box example in Figure~\ref{fig:stallingfixed}, where Figure~\ref{fig:stalling2} replicates the stalling situation from Figure~\ref{fig:baushkeStall} and the fast-forwarding is applied in Figure~\ref{fig:fastforwarding}. The first column illustrates the trajectories of the iterates and their distance to the Eucledian projection computed using an interior point method. The second column shows the half-space activity, where half-space 0 corresponds to the left side of the box, half-space 1 to the top side of the box, and half-space 2 to the line (down-facing normal). In Figure~\ref{fig:stalling2}, the algorithm stalls until iteration 16. From the second column, it can be seen that the algorithm stalls until half-space 0 becomes inactive. 

In Figure~\ref{fig:fastforwarding}, stalling is detected at iteration 1, upon which the algorithm is fast-forwarded using $N_{stall}=15$ iterations, where $N_{stall}$ is computed using Theorem~\ref{thm:nstall}. At iteration 3, the iterates of the modified algorithm arrive where the iterates of the original algorithm arrive at iteration 16. The iterates of the modified algorithm then become identical to those of the original algorithm.

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{stalling_notfixed_situation_2.png}
        \caption{Replication of the stalling situation from Figure~\ref{fig:baushkeStall}.}
        \label{fig:stalling2}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{stalling_fixed_situation_2.png}
        \caption{Modified algorithm with fast-forwarding.}
        \label{fig:fastforwarding}
    \end{subfigure}
    \caption{Dykstra's algorithm applied to the line-box example from Figure~\ref{fig:baushkeStall}. The first column illustrates the trajectories of the iterates and their distance to the Eucledian projection computed using an interior point method. The second column shows the half-space activity, where half-space 0 corresponds to the left side of the box, half-space 1 to the top side of the box, and half-space 0 to the line (down-facing normal).}
    \label{fig:stallingfixed}
\end{figure}

%\section{Additional Ideas}
%
%For the polyhedral case, Dykstra's method can be split into two phases: An first phase of length $N_2$ during which some half-spaces become inactive, and a second phase during which the algorithm iterates between active half-spaces. Note that stalling can only occur during the first phase.
%
%For the first phase, the term $x_m^\Tr f_{[m]} - c_{[m]}$ in~\eqref{eq:km} seems to play an important role: the only way a half-space can become inactive is by obtaining a negative $x_m^\Tr f_{[m]} - c_{[m]}$. In~\cite{DYKSTRAPERKINS}, it is shown that
%\begin{align}
%x_{m+n} =\spanv{x_m, f_0,\dots,f_{n-1}}.
%\end{align}
%Moreover, by examination of~\eqref{eq:dykstra:proj:poly}, if $x_{m+n}+e_m\not\in\mathcal{H}_{[m]}$, we see that
%\begin{align}
%x_{m+n} =x_m + a_{[m]}f_{[m]}-\sum_{i\in \mathcal{I} \backslash [m]} a_i f_i,
%\end{align}
%where $a_i\geq 0$, $a_{[m]}\equiv k_m$, and $\mathcal{I}\eqdef \lbrace 0,\dots,n-1\rbrace$.

\bibliographystyle{plain}
\bibliography{master_bib_abbrev}
\end{document}